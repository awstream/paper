\subsection{Automatic Profiling}
\label{sec:automatic-profiling}

After developers use \maybe{} operators to specify potential degradation
operations, \sysname{} automatically builds an accurate profile. The profile
captures the relationship between \textit{application accuracy} and
\textit{bandwidth consumption} under different combinations of data degradation
operations. We describe the formalism, followed by techniques that efficiently
perform offline and online profiling.

\para{Profiling formalism.} Suppose a stream processing application has $n$
\maybe{} operators. Each operator introduces a knob $k_i$. The combination of
all knobs forms a \textit{configuration} $c = [k_{1}, k_{2}, ... k_{n}]$. The
set of all possible configurations $\mathbb{C}$ is the space that the profiling
explores. For each configuration $c$, there are two mappings that are of
particular interest: a mapping from $c$ to its bandwidth consumption $B(c)$ and
its accuracy measure $A(c)$. \autoref{tab:notations} summarizes these symbols.

The profiling looks for Pareto-optimal configurations; that is, for any
configuration $c$ in the Pareto-optimal set $\mathbb{P}$, there is no
alternative configuration $c'$ that requires less bandwidth and offers a higher
accuracy. Formally, $\mathbb{P}$ is defined as follows:

{\small \vspace{-1em}
  \begin{equation}
  \mathbb{P} = \{ c \in \mathbb{C} : \{ c' \in \mathbb{C}: B(c') < B(c),
  A(c') > A(c) \} = \varnothing\}
  \label{eq:pareto}
\end{equation}
}%

\begin{table}
  \footnotesize
  \centering
  \begin{tabular}{r l}
    \toprule
    \textbf{Symbol} & \textbf{Description} \\
    \midrule
    $n$ & number of degradation operations \\
    $k_i$ & the \textit{i}-th degradation knob \\
    $c = [k_{1}, k_{2}, ... k_{n}]$ & one specific configuration \\
    $\mathbb{C}$ & the set of all configurations \\
    \midrule
    $B(c)$ & bandwidth requirement for $c$ \\
    $A(c)$ & accuracy measure for $c$ \\
    $\mathbb{P}$ & Pareto-optimal set \\
    \midrule
    $c_i$, $c_{i+1}$, $c_{\max}$ & current/next/maximal configuration at runtime \\
    $R$ & network delivery rate (estimated bandwidth) \\
    $\text{Q}_\text{E}$, $\text{Q}_\text{C}$ & messages when \texttt{Queue} is empty or congested \\
    $\text{R}_\text{C}$ & message when \texttt{Receiver} detects congestion \\
    $\text{AC}_\text{Probe}$ & message when \texttt{AC} requests probing \\
    $\text{S}_\text{ProbeDone}$ & message when \texttt{Socket} finishes probing \\
    \bottomrule
  \end{tabular}
  \vspace{0.3em}
  \caption{Notations used in this paper.}
  \label{tab:notations}
  \vspace{-3em}
\end{table}

Because \sysname{} allows arbitrary functions as the degradation functions, it
does not assume a closed-form relationship for $B(c)$ and $A(c)$. Instead,
\sysname{} takes a data-driven approach: profiling applications with
developer-supplied training data.  We measure $B(c)$ at the point of
transmission. The accuracy $A(c)$ is measured either against the groundtruth, or
the reference results when all degradation operations are off.  We show examples
of knobs, configurations, and accuracy functions when we present applications in
\autoref{sec:implementation}.

\para{Offline Profiling.} We first use an offline process to build a bootstrap
profile (or default profile).  \sysname{} makes no assumptions on the
performance models, and thus evaluates all possible configurations.  While all
knobs form a combinatorial space, the offline profiling is only a one-time
process.  We exploit parallelism to reduce the profiling time.  Without any
\textit{a priori} knowledge, all configurations are assigned randomly to
available machines.

% \para{Offline Profiling.} We first use an offline process to build a bootstrap
% profile (or default profile).  Because \sysname{} supports arbitrary
% degradation operations, we need to evaluate all combinations of the
% configurations offline profiling is a one-time process, \sysname{} currently
% performs an exhaustive evaluation of all configurations in $\mathbb{C}$
% despite all knobs form a combinatorial space. Future work could explore
% statistical methods to build performance models with a smaller number of
% training samples~\cite{venkataraman2016ernest, alipourfard2017cherrypick}.
% \sysname{} exploits parallelism when profiling all configurations.  Without
% any \textit{a priori} knowledge, all configurations are assigned randomly to
% all available machines.

\para{Online Profiling:} \sysname{} supports online profiling to continuously
refine the profile. The refinement handles \textit{model drift}, a problem when
the learned profile fails to predict the performance accurately. There are two
challenges with online profiling.  $(i)$~There are no ground-truth labels or
reference data to compute accuracy. Because labeling data is prohibitively labor
intensive and time consuming~\cite{russell2008labelme}, \sysname{} currently
uses raw data (data without degradation) as the reference. At runtime, if the
application streams raw data, it is used for online profiling. Otherwise, we
allocate additional bandwidth to transmit raw data, but only do so when there is
spare capacity. $(ii)$~Exhaustive profiling is expensive. If the profiling takes
too much time, the newly-learned profile may already be stale. \sysname{} uses a
combination of parallelization and sampling to speed up profiling, as below:

\begin{itemize}[leftmargin=*, topsep=3pt]

\item Parallelization with degradation-aware scheduling. Evaluating each
  configuration takes a different amount of time. Typically, an increase in the
  level of degradation leads to a decrease in computation; for example, a
  smaller FPS means fewer images to process. Therefore, we collect processing
  times for each configuration from offline profiling and schedule online
  profiling with longest first schedule (LFS)~\cite{karger2010scheduling} during
  parallelization.

\item Sampling-based profiling. Online profiling can speed up when we sample
  data or configurations. Sampling data reduces the amount of data to process,
  but at a cost of generating a less accurate profile. When sampling
  configuration, we can evaluate a subset of the Pareto-optimal configurations
  and compare their performances with an existing profile. A substantial
  difference, such as more than \SI{1}{Mbps} of bandwidth estimation, triggers a
  full profiling over all configurations to update the current profile.

\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../awstream"
%%% End:

%% LocalWords: ProbeDone th combinatorial runtime parallelization priori
%% LocalWords: LFS mbps groundtruth