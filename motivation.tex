\begin{figure}
  \centering
  \includegraphics[width=.9\linewidth]{figures/aws-variation.pdf}
  \caption{Bandwidth variations throughout the day between Amazon EC2 sites
    (from Ireland to California).}
  \label{fig:bw}
\end{figure}

\begin{figure*}
  \centering
  \includegraphics[width=0.95\linewidth]{figures/motiv-app-specific.pdf}
  \caption{Two streaming application examples. (1) Comparing (a) and (b), the
    figure shows how each dimension affects the performance; (2) Comparing (a)
    and (c), the figure shows how application-specific optimization in one case
    is a poor match for a different case. Figure (c)(d)(g)(h) explains the
    measurement with example frames.}
  \label{fig:app-specific}
\end{figure*}

\section{Motivation}
\label{sec:motivation}

In this section, we examine the gap between high application demands and limited
wide-area bandwidth. We then show that neither manual policies nor
application-specific optimizations solve the problem.

\subsection{Wide-area Streaming Applications}
\label{sec:wide-area-streaming}

\paraf{Video Surveillance:} We envisage a city-wide monitoring system that
aggregates camera feeds---from stationary ground cameras and moving aerial
vehicles---and analyzes video streams in real-time for surveillance, anomaly
detection or business intelligence~\cite{oh2011large}. Traditionally, humans are
involved in analyzing abnormal activities. Recent advances in computer vision
and deep learning have dramatically increased the accuracy for visual scenes
analysis, such as pedestrian detection~\cite{dollar2012pedestrian}, vehicle
tracking~\cite{coifman1998real}, or facial recognition to locate people of
interest~\cite{parkhi2015deep, Lu:2015:SHF:2888116.2888245}. Newer surveillance
systems, such as Dropcam~\cite{dropcam} and Vigil~\cite{zhang2015design}, use
the public Internet and wireless links to reduce the cost of deploying and
running the surveillance network.

% \para{High-frequency IoT Sensors:} Although environmental sensors used to be
% slow and not data-intensive~\cite{atzori2010internet}, increasingly,
% high-frequency, high-precision sensors are deployed. For example, uPMUs monitor
% the electrical grid with a network of 1000 devices; each produces 12 streams of
% 120 Hz high-precision values accurate to 100 ns. This amounts to 1.4 million
% points per second~\cite{andersen2016btrdb}.

\para{Infrastructure Monitoring:} Large organizations today are managing
10--100s of data centers (DCs) and edge clusters
worldwide~\cite{calder2013mapping}. This geo-distributed infrastructure
continuously produces large volumes of data like data access logs, server
monitoring logs, and performance counters~\cite{pu2015low,
  rabkin2014aggregation}. While most log analysis today runs in a batch mode on
a daily basis, there is trend towards analyzing logs in real-time for quicker
optimization. For example, a content distribution network (CDN) can improve the
overall efficiency by optimizing data placement if the access logs can be
processed in real-time.

% We consider the practical issues with deploying these applications in the
% wide-area. Our stand is that these applications face a bigger network
% challenge.  Data generated from the edge often fail to be delivered to the
% processing site because of the scarce and variable bandwidth capacity in the
% wide-area. Once they arrive, existing stream processing systems can easily
% manage a large cluster and perform data analytics at real-time.

\subsection{Wide-area Bandwidth Characteristics}
\label{sec:wide-area-bandwidth}

Recent works on WAN-aware systems have all demonstrated that WAN bandwidth is
insufficient and costly~\cite{pu2015low, vulimiri2015global,
  vulimiri2015wananlytics, hsieh17gaia}. Using Amazon EC2 as a case study, the
WAN bandwidth capacity is 15x smaller than their LAN bandwidth on average, and
up to 60x smaller in the worst case~\cite{hsieh17gaia}. In terms of pricing, as
of April 2017, the average WAN bandwidth cost is up to 38x of the cost of
renting two machines~\cite{amazon2017pricing}.

In addition to the scarcity and cost, the variability also affects our WAN
streaming workload. We conducted a day-long measurement using
iPerf~\cite{iperf3} to measure the pair-wise bandwidth between four Amazon EC2
sites. The results show large variance in all pairs, and \autoref{fig:bw} is one
such pair. There are occasions that available bandwidth is below 25\% of the
maximum bandwidth.

The back-haul links between EC2 sites are better---if not at least
representative---in comparison to general WAN links. Similar scarcity and
variations have been reported in wireless networks~\cite{biswas2015large},
broadband access networks~\cite{grover2013peeking, sundaresan2014bismark} and
cellular networks~\cite{nikravesh2014mobile}.

\subsection{Making the Case for a System Approach}
\label{sec:making-case-sys-approach}

In addressing the bandwidth limits, existing solutions include manual policies
or application-specific solutions. We discuss their drawbacks to make the case
for a system approach.

\para{Manual polices are sub-optimal.} While existing works such as
JetStream~\cite{rabkin2014aggregation} and DASH~\cite{sodagar2011mpeg} allow
adaptation, they require developers to write manual policies. We discuss the
issues with manual policies with the following example: \textit{if bandwidth is
  insufficient, switch to sending images at 75\% fidelity, then 50\% if there
  still isn't enough bandwidth. Beyond that point, reduce the frame rate, but
  keep the image fidelity.}

The policy is not accurate. Developers write such rules based on heuristics and
don't back it up with measurements. Seventy-five percent fidelity does not
necessarily lead to 75\% application accuracy. In terms of bandwidth, naively
one would think that reducing the frame rate by by half will also half the data
rate. However, if video encoding such as H.264~\cite{richardson2011h} is used,
when we reduce the frame rate, it increases the inter-frame difference and
creates larger P-frames. \autoref{fig:app-specific}(e) shows that reducing the
frame rate to one-third, the bandwidth consumption is still more than 50\%.

Such specification is not scalable. When the policy involves multiple dimensions
or developers desire a fine-grain control, the policy will end up with too many
rules.  Writing such rules manually is a tedious and error-prone process.

The abstraction is low-level. Developers are forced to study and measure the
impact of individual operations, prohibiting its wide adoption in practice.

\para{Application-specific solutions don't generalize.} Because each application
has a different performance metric, relies on different features, targets at
different data distributions, a fine-tuned policy for one application will work
poorly when applied to another application.

Analytical applications have their own goals, entailing different metrics to
optimize. Traditional video streaming focuses on end-users'
experience~\cite{yin2015control, michalos2012dynamic, pantos2016http}. If we
transfer their techniques to machine-based video analytics, the system maintains
an unnecessarily-high frame rate.

Each algorithm relies on different features from the data. For example, many
computer vision detection algorithms depend on the edge
information~\cite{canny1986computational, lowe2004distinctive, viola2001rapid}
while object tracking applications~\cite{allen2004object} work best when the
inter-frame difference is small. The former is sensitive to resolution while the
latter to frame rate.

Similar applications face different data distributions. Compare the stationary
camera detecting pedestrians with the mobile camera recognizing objects
(\autoref{fig:app-specific}). In the former case, when we take the pedestrians'
walking speed into consideration, a high frame rate is not necessary. But
high-resolution images are crucial as surveillance cameras are far from the
targets. In the latter case, mobile cameras move. Reducing the frame rate
introduces significant errors.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "sosp17"
%%% End:
