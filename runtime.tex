\subsection{Runtime Adaptation}
\label{sec:runtime}

\begin{figure}
  \centering
  % \resizebox{\columnwidth}{!}{
  %   \input{runtime-diagram}
  % }
  \includegraphics[width=\linewidth]{figures/runtime-adaptation.pdf}
  \caption{Runtime adaptation system architecture.}
  \label{fig:runtime}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/cc.pdf}
  \caption{The Adaptation Algorithm and an illustration of one possible trace.}
  \label{fig:cc}
\end{figure}

At runtime, \sysname{} creates additional modules and controls to facillitate
the runtime adaptation (\autoref{fig:runtime}).

The source stream has a \texttt{Degrade} module derived from \maybe{} that
allows the controller to \textit{update} the level of degradation. Data
generated by the source is then enqueued to a \texttt{Queue} module and
subsequently dequeued by \texttt{Socket}. When the source's data generation rate
exceeds the socket's departure rate, the queue grows. At this time, adaptation
controller (AC) starts regulating the source stream by changing the
configuration. We denote the current configuration is $c_i$. The AC's algorithm
(a state machine \autoref{fig:cc}) is described as below:

\para{Startup: rapid growth.} When the application starts up, it performs its
first and most rapid rate increase. Upon each \texttt{Q.NoQueue} message, it
advances the configuration from $c_i$ to $c_{i+1}$, increasing the data rate
discretely. The growth stops if it receives \texttt{Q.Congestion} (turning into
\texttt{Degrade} state) or $c_{i+1} == c_{max}$ (entering \texttt{Steady}
state).

\para{Degrade: reacting to congestion.} At this state, there are queued objects
hurting the application latency. AC queries the current delivery rate $R$ from
the \texttt{Socket} and \textit{update} the \texttt{Degrade} module with a
configuration $c_i$ such that $B(c_i) < \alpha R$ ($\alpha \in (0, 1)$). A
smaller $\alpha$ allows a quicker drain of the queue. After there is no more
queued objects, AC receives \texttt{Q.NoQueue} signal and enters \texttt{Steady}
state.

\para{Steady: achieving low latency delivery.} Applications achieve low latency
by spending most of its time in this \texttt{Steady} state. If the network
condition changes and the delivery bandwidth is not sufficient, the queue's
growth will reflect it and \texttt{Q.Congestion} signal will change the state to
\texttt{Degrade}. In \texttt{Steady} state, if the application is running at
maximal configuration $c_{max}$, then it will stay in this state; if current
$c_i < c_{max}$, AC will enter \texttt{Probe} state to check if there is more
available bandwidth.

\para{Probe: more bandwidth for a higher accuracy.} During the probe, the
\texttt{Socket} will send additional traffic and update the bandwidth
estimation. Instead of directly advance $c_i$, which could lead to queue and
drastic latency increase, the probing sends \textit{additional} traffic so that
the rate can be controlled in a finer granularity. If the application is
cofnigured to run online profiling, \sysname{} sends raw data as the additional
traffic; otherwise, dummy data is sent for probing. AC leaves probing state
under two conditions: (1) the available bandwith $R$ is large enough for the
next configuration $B(c_{i+1}) < R$ (\texttt{S.ProbeDone}); (2) objects are
queued (\texttt{Q.Congestion}) due to probing.

If online profiling is enabled, \texttt{Receiver} at the server side will
extract raw data and send it to online profiler. The newly-learned model is then
fed back to AC to update the profile for subsequent adaptation.

% \begin{figure}
%   \centering
%   \resizebox{\columnwidth}{!}{
%     \input{congestion-control}
%   }
%   \caption{Congestion Control Algorithm}
%   \label{fig:cc}
% \end{figure}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "sosp17"
%%% End:
