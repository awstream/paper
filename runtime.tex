\begin{figure}
  \centering
  % \resizebox{\columnwidth}{!}{
  %   \input{runtime-diagram}
  % }
  \includegraphics[width=\linewidth]{figures/runtime-adaptation.pdf}
  \caption{Runtime adaptation system architecture.}
  \label{fig:runtime}
\end{figure}

\subsection{Runtime Adaptation}
\label{sec:runtime}

At runtime, \sysname{} performs application adaptation according to the learned
profile. We choose to design our own runtime system and adaptation algorithm
because prior solutions are not satisfactory: $(i)$~network protocols adapt to
available resources without application accuracy guarantee; $(ii)$
JetStream~\cite{rabkin2014aggregation} uses manual policies without the
bandwidth demand of each rule, therefore it can only react slowly and adapt
gradually, causing high latency; $(iii)$~video streaming adaptation, such as
Huang et. al~\cite{huang2014buffer}, relies on the playback buffer and incurs
high latency.

\autoref{fig:runtime} shows our runtime system architecture. \sysname{}
applications' source contains a \texttt{Maybe} module derived from all \maybe{}
operations. This module allows the controller to update the level of
degradation. Data generated by the source is then enqueued to \texttt{Queue} and
subsequently dequeued by \texttt{Socket}. When the data generation rate exceeds
\texttt{Socket}'s departure rate, the queue grows. At this time, the adaptation
controller (AC) queries the estimated bandwidth from \texttt{Socket} and
regulates the source stream by updating the configuration.  After the data is
sent through the network, the receiver extracts raw data to the online profiler
and delivers data to the application analytics. Raw data is only transmitted
when the queue is empty. When a new profile is learned, it is fed back to AC for
subsequent adaptation.

The adaptation algorithm is shown in \autoref{fig:cc}. AC loads the profile and
sorts all configurations with an ascending order of bandwidth demand, getting a
list $[c_1, \dots, c_{\max}]$. The current configuration is $c_i$ and the next
$c_{i+1}$. AC receives messages from the \texttt{Queue}: message \qe{} when the
queue is empty and $\text{Q}_\text{C}$ when queued items exceed a threshold. AC
can query \texttt{Socket} for delivery rate $R$ or request it to probe for a
target bandwidth, often $B(c_{i+1})$. When $R > B(c_{i+1})$, \texttt{Socket}
sends back \spd{}. The algorithm follows a state machine:

\begin{itemize}[leftmargin=*]

\item \textbf{Startup: rapid growth.} \sysname{} starts with $c_1$ and grows the
  rate ($c_i \Rightarrow c_{i+1}$) upon each \qe{}. The growth stops at
  $c_{\max}$ (to \texttt{Steady}) or if it receives \qc{} (to \texttt{Degrade}).

\item \textbf{Degrade: reacting to congestion.} When objects are queued, AC
  receives \qc{} and runs \texttt{adapt()} procedure. This involves two steps:
  (1) AC queries $R$ from \texttt{Socket}; (2) AC updates \texttt{Maybe} with
  $c$ such that $B(c) < \alpha R, \alpha \in (0, 1)$. A smaller $\alpha$ allows
  a quicker draining of the queue. \sysname{} changes to \texttt{Steady} after
  the queue is drained.

\item \textbf{Steady: low latency delivery.} \sysname{} achieves low latency by
  spending most of the time in the \texttt{Steady} state. It changes to
  \texttt{Degrade} when congestion occurs. If $c < c_{\max}$ and it receives
  \qe{}, AC enters the \texttt{Probe} state to check for more available
  bandwidth.

\item \textbf{Probe: more bandwidth for a higher accuracy.} Advancing $c$
  directly causes a drastic latency increase when $B(c_{i+1}) \gg B(c_i)$. To
  allow a smooth increase, AC requests \texttt{Socket} to probe by sending
  additional traffic controlled by \texttt{probe\_gain} (in
  \texttt{inc\_pace()}, similar to BBR~\cite{cardwell2017bbr}). \sysname{} stops
  probing under two conditions: (1) upon \spd{}, it advances $c_i$; (2) upon
  \qc{}, it returns to \texttt{Steady}.

\end{itemize}

\begin{figure}
  \begin{subfigure}[t]{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{figures/cc.pdf}
    \caption{Rate adaptation as a state machine.}
    \vspace{1em}
    \label{fig:cc-sm}
  \end{subfigure}
  \begin{subfigure}[t]{0.95\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{figures/cc2.pdf}
    \caption{An example to illustrate the adaptation algorithm.}
    \label{fig:cc-ex}
  \end{subfigure}

  \caption{The adaptation algorithm as a state machine and an illustration of
    one possible trace showing state transitions.}
  \label{fig:cc}
\end{figure}

% \begin{figure}
%   \centering
%   \resizebox{\columnwidth}{!}{
%     \input{congestion-control}
%   }
%   \caption{Congestion Control Algorithm}
%   \label{fig:cc}
% \end{figure}

\para{Resource Allocation and Fairness:} In addition to rate adaptation, the
profile is also useful for controlling the bandwidth usage of a single
application or allocating resources among competing tasks.

For individual applications, developers can pinpoint a configuration for a given
bandwidth or accuracy goal. They can also specify criterion to limit effective
configurations. For example, \sysname{} can enforce an upper bound on the
bandwidth consumption. Such a limit is extremely useful to reduce WAN bandwidth
cost.

For multiple applications, their profiles allows novel bandwidth allocation
schemes such as utility fairness. Different from traditional resource fairness
where applications get equal share of bandwidth, \textit{utility fairness} aims
to maximize the \textit{minimal} application accuracy. With the profiles,
finding allocations is equivalent of finding proper configuration $c^t$ for
application $t$. We formulate utility fairness as follows:

\begin{equation}
  \label{eq:multitask}
  \underset{c^t}{\max} \; \min({A^t(c^t)})
  \;
  \text{s.t.}
  \;
  \sum_t{B^t(c^t)} < R
\end{equation}

Solving this optimization is computationally hard. \sysname{} uses a heuristics
approach. We start with $c_1^t$ and improve the application $t$ that has the
worst accuracy. This process is repeated until all available bandwidth is
allocated.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "sosp17"
%%% End:
